{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 0.02804564313992578, 1: 0.012977339196610205, 2: 0.012977806686940282, 3: 0.013365603718374572, 4: 0.012739279439020666, 5: 0.012382866065396078, 6: 0.013358472248808886, 7: 0.01316349273102362, 8: 0.012754027105980299, 9: 0.013582352492204814, 10: 0.012758875777948143, 11: 0.012573076636214353, 12: 0.012972364562050984, 13: 0.01356962264732801, 14: 0.012586684669714698, 15: 0.012954432105762598, 16: 0.013169136470457837, 17: 0.012563312025285817, 18: 0.012360951766489346, 19: 0.012573789447021214, 20: 0.012762861060670537, 21: 0.01356962264732801, 22: 0.01337413598133555, 23: 0.012377161026521808, 24: 0.013570372350671286, 25: 0.01255508804888208, 26: 0.013194183224568608, 27: 0.013180330762569388, 28: 0.012963642432516746, 29: 0.013160190308405418, 30: 0.013374917142297197, 31: 0.011984023573724837, 32: 0.012566714942516294, 33: 0.01218148015930462, 34: 0.013577147888306806, 35: 0.01337971723297183, 36: 0.013168173063039596, 37: 0.012984918552873951, 38: 0.01295730088495268, 39: 0.012763706096499546, 40: 0.012958637720113499, 41: 0.013154453319855448, 42: 0.027632462467736083, 43: 0.027349346374952434, 44: 0.026831254323054964, 45: 0.026229014586286, 46: 0.02622013750757412, 47: 0.02579754808133866, 48: 0.025354242651691006, 49: 0.02482898366950527, 50: 0.024528738643988905, 51: 0.024370531689946497, 52: 0.02385698810703861, 53: 0.023461463241466772, 54: 0.022907668849390307, 55: 0.02278067112860343, 56: 0.02259850428439425, 57: 0.022132866258313247, 58: 0.02224883018433758, 59: 0.021682840597897948}\n"
     ]
    }
   ],
   "source": [
    "#Source: https://www.geeksforgeeks.org/page-rank-algorithm-implementation/\n",
    "\n",
    "def pagerank(G, alpha=0.85, personalization=None,\n",
    "\t\t\tmax_iter=100, tol=1.0e-6, nstart=None, weight='weight',\n",
    "\t\t\tdangling=None):\n",
    "\t\"\"\"Return the PageRank of the nodes in the graph.\n",
    "\n",
    "\tPageRank computes a ranking of the nodes in the graph G based on\n",
    "\tthe structure of the incoming links. It was originally designed as\n",
    "\tan algorithm to rank web pages.\n",
    "\n",
    "\tParameters\n",
    "\t----------\n",
    "\tG : graph\n",
    "\tA NetworkX graph. Undirected graphs will be converted to a directed\n",
    "\tgraph with two directed edges for each undirected edge.\n",
    "\n",
    "\talpha : float, optional\n",
    "\tDamping parameter for PageRank, default=0.85.\n",
    "\n",
    "\tpersonalization: dict, optional\n",
    "\tThe \"personalization vector\" consisting of a dictionary with a\n",
    "\tkey for every graph node and nonzero personalization value for each node.\n",
    "\tBy default, a uniform distribution is used.\n",
    "\n",
    "\tmax_iter : integer, optional\n",
    "\tMaximum number of iterations in power method eigenvalue solver.\n",
    "\n",
    "\ttol : float, optional\n",
    "\tError tolerance used to check convergence in power method solver.\n",
    "\n",
    "\tnstart : dictionary, optional\n",
    "\tStarting value of PageRank iteration for each node.\n",
    "\n",
    "\tweight : key, optional\n",
    "\tEdge data key to use as weight. If None weights are set to 1.\n",
    "\n",
    "\tdangling: dict, optional\n",
    "\tThe outedges to be assigned to any \"dangling\" nodes, i.e., nodes without\n",
    "\tany outedges. The dict key is the node the outedge points to and the dict\n",
    "\tvalue is the weight of that outedge. By default, dangling nodes are given\n",
    "\toutedges according to the personalization vector (uniform if not\n",
    "\tspecified). This must be selected to result in an irreducible transition\n",
    "\tmatrix (see notes under google_matrix). It may be common to have the\n",
    "\tdangling dict to be the same as the personalization dict.\n",
    "\n",
    "\tReturns\n",
    "\t-------\n",
    "\tpagerank : dictionary\n",
    "\tDictionary of nodes with PageRank as value\n",
    "\n",
    "\tNotes\n",
    "\t-----\n",
    "\tThe eigenvector calculation is done by the power iteration method\n",
    "\tand has no guarantee of convergence. The iteration will stop\n",
    "\tafter max_iter iterations or an error tolerance of\n",
    "\tnumber_of_nodes(G)*tol has been reached.\n",
    "\n",
    "\tThe PageRank algorithm was designed for directed graphs but this\n",
    "\talgorithm does not check if the input graph is directed and will\n",
    "\texecute on undirected graphs by converting each edge in the\n",
    "\tdirected graph to two edges.\n",
    "\t\"\"\"\n",
    " \n",
    "\tif len(G) == 0:\n",
    "\t\treturn {}\n",
    "\n",
    "\tif not G.is_directed():\n",
    "\t\tD = G.to_directed()\n",
    "\telse:\n",
    "\t\tD = G\n",
    "\n",
    "\t# Create a copy in (right) stochastic form\n",
    "\tW = nx.stochastic_graph(D, weight=weight)\n",
    "\tN = W.number_of_nodes()\n",
    "\n",
    "\t# Choose fixed starting vector if not given\n",
    "\tif nstart is None:\n",
    "\t\tx = dict.fromkeys(W, 1.0 / N)\n",
    "\telse:\n",
    "\t\t# Normalized nstart vector\n",
    "\t\ts = float(sum(nstart.values()))\n",
    "\t\tx = dict((k, v / s) for k, v in nstart.items())\n",
    "\n",
    "\tif personalization is None:\n",
    "\n",
    "\t\t# Assign uniform personalization vector if not given\n",
    "\t\tp = dict.fromkeys(W, 1.0 / N)\n",
    "\telse:\n",
    "\t\tmissing = set(G) - set(personalization)\n",
    "\t\tif missing:\n",
    "\t\t\traise NetworkXError('Personalization dictionary '\n",
    "\t\t\t\t\t\t\t\t'must have a value for every node. '\n",
    "\t\t\t\t\t\t\t\t'Missing nodes %s' % missing)\n",
    "\t\ts = float(sum(personalization.values()))\n",
    "\t\tp = dict((k, v / s) for k, v in personalization.items())\n",
    "\n",
    "\tif dangling is None:\n",
    "\n",
    "\t\t# Use personalization vector if dangling vector not specified\n",
    "\t\tdangling_weights = p\n",
    "\telse:\n",
    "\t\tmissing = set(G) - set(dangling)\n",
    "\t\tif missing:\n",
    "\t\t\traise NetworkXError('Dangling node dictionary '\n",
    "\t\t\t\t\t\t\t\t'must have a value for every node. '\n",
    "\t\t\t\t\t\t\t\t'Missing nodes %s' % missing)\n",
    "\t\ts = float(sum(dangling.values()))\n",
    "\t\tdangling_weights = dict((k, v/s) for k, v in dangling.items())\n",
    "\tdangling_nodes = [n for n in W if W.out_degree(n, weight=weight) == 0.0]\n",
    "\n",
    "\t# power iteration: make up to max_iter iterations\n",
    "\tfor _ in range(max_iter):\n",
    "\t\txlast = x\n",
    "\t\tx = dict.fromkeys(xlast.keys(), 0)\n",
    "\t\tdanglesum = alpha * sum(xlast[n] for n in dangling_nodes)\n",
    "\t\tfor n in x:\n",
    "\n",
    "\t\t\t# this matrix multiply looks odd because it is\n",
    "\t\t\t# doing a left multiply x^T=xlast^T*W\n",
    "\t\t\tfor nbr in W[n]:\n",
    "\t\t\t\tx[nbr] += alpha * xlast[n] * W[n][nbr][weight]\n",
    "\t\t\tx[n] += danglesum * dangling_weights[n] + (1.0 - alpha) * p[n]\n",
    "\n",
    "\t\t# check convergence, l1 norm\n",
    "\t\terr = sum([abs(x[n] - xlast[n]) for n in x])\n",
    "\t\tif err < N*tol:\n",
    "\t\t\treturn x\n",
    "\traise NetworkXError('pagerank: power iteration failed to converge '\n",
    "\t\t\t\t\t\t'in %d iterations.' % max_iter)\n",
    "\n",
    "\n",
    "import networkx as nx\n",
    "G=nx.barabasi_albert_graph(60,41)\n",
    "pr=nx.pagerank(G,0.4)\n",
    "print(pr)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
